{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2318028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans\n",
      "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting httpx==0.13.3\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 55.1/55.1 kB 1.4 MB/s eta 0:00:00\n",
      "Collecting chardet==3.*\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "     -------------------------------------- 133.4/133.4 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting rfc3986<2,>=1.3\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting idna==2.*\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.8/58.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: sniffio in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans) (1.2.0)\n",
      "Collecting hstspreload\n",
      "  Downloading hstspreload-2024.3.1-py3-none-any.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 1.8 MB/s eta 0:00:00\n",
      "Collecting httpcore==0.9.*\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.6/42.6 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans) (2023.5.7)\n",
      "Collecting h2==3.*\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.0/65.0 kB ? eta 0:00:00\n",
      "Collecting h11<0.10,>=0.8\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "     ---------------------------------------- 53.6/53.6 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting hpack<4,>=3.0\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting hyperframe<6,>=5.2.0\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py): started\n",
      "  Building wheel for googletrans (setup.py): finished with status 'done'\n",
      "  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=15777 sha256=d3ba0fb734fa0443adea804c22ea9224f20229468d19f699aa0612241fe19256\n",
      "  Stored in directory: c:\\users\\mouadkhaznaoui\\appdata\\local\\pip\\cache\\wheels\\cd\\ca\\87\\9a9849f1ceedf19652e3fc8a5bf2bd5b2e151b7b158c79bf5b\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 4.0.0\n",
      "    Uninstalling chardet-4.0.0:\n",
      "      Successfully uninstalled chardet-4.0.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "Successfully installed chardet-3.0.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.3.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.27 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.27 requires nbformat==5.4.0, but you have nbformat 5.7.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdc08e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deep_translator\n",
      "  Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.3/42.3 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from deep_translator) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from deep_translator) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.3.2.post1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.0.4)\n",
      "Installing collected packages: deep_translator\n",
      "Successfully installed deep_translator-1.11.4\n"
     ]
    }
   ],
   "source": [
    "!pip install deep_translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "030faa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting wikipedia-api\n",
      "  Downloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\n",
      "Collecting googletrans==4.0.0-rc1\n",
      "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: httpx==0.13.3 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.2.0)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
      "Requirement already satisfied: idna==2.* in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
      "Requirement already satisfied: chardet==3.* in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
      "Requirement already satisfied: hstspreload in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==0.9.* in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from wikipedia-api) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from requests->wikipedia-api) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from requests->wikipedia-api) (2.0.4)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py): started\n",
      "  Building wheel for googletrans (setup.py): finished with status 'done'\n",
      "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17461 sha256=20eb714e350991744a0696c623d5e2216a8c2a8a009c946cd3f04df201e9d8af\n",
      "  Stored in directory: c:\\users\\mouadkhaznaoui\\appdata\\local\\pip\\cache\\wheels\\54\\ca\\27\\562b6eac3a495887e4b44bac3a1efe925fa603d085ba89a21d\n",
      "Successfully built googletrans\n",
      "Installing collected packages: wikipedia-api, googletrans\n",
      "  Attempting uninstall: googletrans\n",
      "    Found existing installation: googletrans 3.0.0\n",
      "    Uninstalling googletrans-3.0.0:\n",
      "      Successfully uninstalled googletrans-3.0.0\n",
      "Successfully installed googletrans-4.0.0rc1 wikipedia-api-0.6.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install wikipedia-api googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a713d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from wikipedia) (4.11.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from wikipedia) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.3.2.post1)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11707 sha256=71a85ae343a21466ba7402cc0db5254cb5b413b29dfcebd02546cc8cd9c6db54\n",
      "  Stored in directory: c:\\users\\mouadkhaznaoui\\appdata\\local\\pip\\cache\\wheels\\b2\\7f\\26\\524faff9145e274da278dc97d63ab0bfde1f791ecf101a9c95\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0df5c046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting translate\n",
      "  Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\n",
      "Collecting libretranslatepy==2.1.1\n",
      "  Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from translate) (4.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from translate) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from translate) (2.28.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from click->translate) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from requests->translate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from requests->translate) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from requests->translate) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from requests->translate) (2023.5.7)\n",
      "Installing collected packages: libretranslatepy, translate\n",
      "Successfully installed libretranslatepy-2.1.1 translate-3.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f04defb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langid\n",
      "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 2.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\mouadkhaznaoui\\anaconda3\\lib\\site-packages (from langid) (1.23.5)\n",
      "Building wheels for collected packages: langid\n",
      "  Building wheel for langid (setup.py): started\n",
      "  Building wheel for langid (setup.py): finished with status 'done'\n",
      "  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941179 sha256=63ddebce555ac3fdd8c194c078f46b5b75da07d7f0f11a2fbb8d468c24d4bb4f\n",
      "  Stored in directory: c:\\users\\mouadkhaznaoui\\appdata\\local\\pip\\cache\\wheels\\50\\68\\3c\\b4aa22e9fad6f19c23a12682bb2d94fc3615b25fe60b84936b\n",
      "Successfully built langid\n",
      "Installing collected packages: langid\n",
      "Successfully installed langid-1.1.6\n"
     ]
    }
   ],
   "source": [
    "!pip install langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35a10315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les fichiers ont été fusionnés avec succès !\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "def regrouper_par_colonne(fichier_1, fichier_2, colonne):\n",
    "    # Dictionnaire pour stocker les lignes regroupées par la valeur de la colonne spécifiée\n",
    "    lignes_regroupees = defaultdict(list)\n",
    "\n",
    "    # Charger le premier fichier TSV et regrouper par la colonne spécifiée\n",
    "    with open(fichier_1, 'r', newline='', encoding='utf-8') as f1:\n",
    "        lecteur = csv.DictReader(f1, delimiter='\\t')\n",
    "        for ligne in lecteur:\n",
    "            sent_id = ligne[colonne]\n",
    "            lignes_regroupees[sent_id].append(ligne)\n",
    "\n",
    "    # Charger le deuxième fichier TSV et regrouper par la même colonne\n",
    "    with open(fichier_2, 'r', newline='', encoding='utf-8') as f2:\n",
    "        lecteur = csv.DictReader(f2, delimiter='\\t')\n",
    "        for ligne in lecteur:\n",
    "            sent_id = ligne[colonne]\n",
    "            lignes_regroupees[sent_id].append(ligne)\n",
    "\n",
    "    # Fusionner les données regroupées en un seul ensemble de données\n",
    "    ensemble_de_donnees = []\n",
    "    for sent_id, lignes in lignes_regroupees.items():\n",
    "        # Créer un dictionnaire avec la colonne sentID.BTEC et chaque colonne distincte\n",
    "        ligne_fusionnee = {'sentID.BTEC': sent_id}\n",
    "        for ligne in lignes:\n",
    "            for colonne, valeur in ligne.items():\n",
    "                if colonne != colonne_a_regrouper:\n",
    "                    nouvelle_colonne = f\"{colonne}_{ligne['lang']}\"\n",
    "                    ligne_fusionnee[nouvelle_colonne] = valeur\n",
    "        ensemble_de_donnees.append(ligne_fusionnee)\n",
    "\n",
    "    return ensemble_de_donnees\n",
    "\n",
    "def ecrire_dans_tsv(ensemble_de_donnees, fichier_sortie):\n",
    "    # Écrire les données fusionnées dans un nouveau fichier TSV\n",
    "    with open(fichier_sortie, 'w', newline='', encoding='utf-8') as f:\n",
    "        colonnes = ensemble_de_donnees[0].keys()\n",
    "        ecrivain = csv.DictWriter(f, fieldnames=colonnes, delimiter='\\t')\n",
    "        ecrivain.writeheader()\n",
    "        for ligne in ensemble_de_donnees:\n",
    "            ecrivain.writerow(ligne)\n",
    "\n",
    "# Utilisation du script\n",
    "fichier_1 = 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR.corpus.Rabat.tsv'\n",
    "fichier_2 = 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR.corpus.MSA.tsv'\n",
    "colonne_a_regrouper = 'sentID.BTEC'\n",
    "fichier_sortie = 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR_fusionne_2.tsv'\n",
    "\n",
    "donnees_fusionnees = regrouper_par_colonne(fichier_1, fichier_2, colonne_a_regrouper)\n",
    "ecrire_dans_tsv(donnees_fusionnees, fichier_sortie)\n",
    "\n",
    "print(\"Les fichiers ont été fusionnés avec succès !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51a59f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nouveau fichier a été créé avec succès, les colonnes 'lang_RAB' et 'lang_MSA' ont été supprimées.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def ecrire_dans_csv_sans_lang(ensemble_de_donnees, fichier_sortie):\n",
    "    # Liste des colonnes à exclure\n",
    "    colonnes_a_exclure = ['lang_RAB', 'lang_MSA', 'split_MSA']\n",
    "\n",
    "    # Écrire les données fusionnées dans un nouveau fichier CSV\n",
    "    with open(fichier_sortie, 'w', newline='', encoding='utf-8') as f:\n",
    "        # Récupérer les colonnes à écrire (toutes sauf celles à exclure)\n",
    "        colonnes = [colonne for colonne in ensemble_de_donnees[0].keys() if colonne not in colonnes_a_exclure]\n",
    "        ecrivain = csv.DictWriter(f, fieldnames=colonnes)\n",
    "        ecrivain.writeheader()\n",
    "        for ligne in ensemble_de_donnees:\n",
    "            # Créer une nouvelle ligne sans les colonnes à exclure\n",
    "            nouvelle_ligne = {colonne: valeur for colonne, valeur in ligne.items() if colonne not in colonnes_a_exclure}\n",
    "            ecrivain.writerow(nouvelle_ligne)\n",
    "\n",
    "# Utilisation du script\n",
    "fichier_fusionne = 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR_fusionne_2.tsv'\n",
    "fichier_sortie_sans_lang = 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR_fusionne_7.csv'\n",
    "\n",
    "ecrire_dans_csv_sans_lang(donnees_fusionnees, fichier_sortie_sans_lang)\n",
    "\n",
    "print(\"Le nouveau fichier a été créé avec succès, les colonnes 'lang_RAB' et 'lang_MSA' ont été supprimées.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9eea1771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nouveau fichier CSV final a été créé avec succès.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def ecrire_dans_csv_sans_lang_et_split(ensemble_de_donnees, fichier_sortie):\n",
    "    # Liste des colonnes à exclure\n",
    "    colonnes_a_exclure = ['lang_RAB', 'lang_MSA', 'split_RAB','split_MSA']\n",
    "\n",
    "    # Écrire les données fusionnées dans un nouveau fichier CSV\n",
    "    with open(fichier_sortie, 'w', newline='', encoding='utf-8') as f:\n",
    "        # Récupérer les colonnes à écrire (toutes sauf celles à exclure)\n",
    "        colonnes = [colonne for colonne in ensemble_de_donnees[0].keys() if colonne not in colonnes_a_exclure]\n",
    "        ecrivain = csv.DictWriter(f, fieldnames=colonnes)\n",
    "        ecrivain.writeheader()\n",
    "        for ligne in ensemble_de_donnees:\n",
    "            # Créer une nouvelle ligne sans les colonnes à exclure\n",
    "            nouvelle_ligne = {colonne: valeur for colonne, valeur in ligne.items() if colonne not in colonnes_a_exclure}\n",
    "            ecrivain.writerow(nouvelle_ligne)\n",
    "            \n",
    "# Utilisation du script\n",
    "fichier_fusionne = 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR_fusionne_2.tsv'\n",
    "fichier_sortie_sans_lang = 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR_fusionne_6.csv'\n",
    "\n",
    "ecrire_dans_csv_sans_lang(donnees_fusionnees, fichier_sortie_sans_lang)\n",
    "\n",
    "print(\"Le nouveau fichier CSV final a été créé avec succès.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a794f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les premières 3 lignes de la colonne sent_RAB sont :\n",
      "0    إنها في أخر القاعة . سوف آتي لك ببعض منها الآن...\n",
      "1                             هل تقومون بعمل تعديلات ؟\n",
      "2                           نريد مائدة بجانب النافذة .\n",
      "Name: sent_MSA, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chemin vers votre fichier CSV\n",
    "chemin_fichier_csv = 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR_fusionne_7.csv'\n",
    "\n",
    "# Lire les premières 3 lignes de la colonne sent_RAB\n",
    "try:\n",
    "    colonne_sent_RAB = pd.read_csv(chemin_fichier_csv, usecols=['sent_MSA'], nrows=3)['sent_MSA']\n",
    "    print(\"Les premières 3 lignes de la colonne sent_RAB sont :\")\n",
    "    print(colonne_sent_RAB)\n",
    "except FileNotFoundError:\n",
    "    print(\"Le fichier spécifié n'a pas été trouvé.\")\n",
    "except KeyError:\n",
    "    print(\"La colonne 'sent_RAB' n'existe pas dans le fichier CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e86f6c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MouadKHAZNAOUI\\AppData\\Local\\Temp\\ipykernel_6924\\2438746871.py:10: FutureWarning: this method is deprecated in favour of `Styler.to_html()`\n",
      "  display(HTML(df.head(10).style.set_table_styles([{'selector': 'th', 'props': [('background', '#F0F8FF')]}]).render()))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c53c1 th {\n",
       "  background: #F0F8FF;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c53c1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c53c1_level0_col0\" class=\"col_heading level0 col0\" >sentID.BTEC</th>\n",
       "      <th id=\"T_c53c1_level0_col1\" class=\"col_heading level0 col1\" >split_RAB</th>\n",
       "      <th id=\"T_c53c1_level0_col2\" class=\"col_heading level0 col2\" >sent_RAB</th>\n",
       "      <th id=\"T_c53c1_level0_col3\" class=\"col_heading level0 col3\" >sent_MSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c53c1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c53c1_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_c53c1_row0_col1\" class=\"data row0 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_c53c1_row0_col2\" class=\"data row0 col2\" >كاين في اللاخر ديال هاد القاعة. انجيب ليك شويا دابا. و إلا حتاجيتي شي حاجا اخرى، قولها ليا.</td>\n",
       "      <td id=\"T_c53c1_row0_col3\" class=\"data row0 col3\" >إنها في أخر القاعة . سوف آتي لك ببعض منها الآن . إذا أردت أي شيئاً آخر فقط أعلمني .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c53c1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c53c1_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_c53c1_row1_col1\" class=\"data row1 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_c53c1_row1_col2\" class=\"data row1 col2\" >واش كا دير التعديلات؟</td>\n",
       "      <td id=\"T_c53c1_row1_col3\" class=\"data row1 col3\" >هل تقومون بعمل تعديلات ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c53c1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c53c1_row2_col0\" class=\"data row2 col0\" >4</td>\n",
       "      <td id=\"T_c53c1_row2_col1\" class=\"data row2 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_c53c1_row2_col2\" class=\"data row2 col2\" >بغينا ناخدو طابلة حدا الشرجم.</td>\n",
       "      <td id=\"T_c53c1_row2_col3\" class=\"data row2 col3\" >نريد مائدة بجانب النافذة .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c53c1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c53c1_row3_col0\" class=\"data row3 col0\" >5</td>\n",
       "      <td id=\"T_c53c1_row3_col1\" class=\"data row3 col1\" >corpus-6-test-corpus-26-train</td>\n",
       "      <td id=\"T_c53c1_row3_col2\" class=\"data row3 col2\" >راه تما، مقابل مكتب استعلامات السياح بالضبط.</td>\n",
       "      <td id=\"T_c53c1_row3_col3\" class=\"data row3 col3\" >هناك ، أمام بيانات السائح تماما .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c53c1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c53c1_row4_col0\" class=\"data row4 col0\" >9</td>\n",
       "      <td id=\"T_c53c1_row4_col1\" class=\"data row4 col1\" >corpus-6-test-corpus-26-train</td>\n",
       "      <td id=\"T_c53c1_row4_col2\" class=\"data row4 col2\" >ما عمري سمعت هاد العنوان هنايا.</td>\n",
       "      <td id=\"T_c53c1_row4_col3\" class=\"data row4 col3\" >لم اسمع بهذا العنوان من قبل بالقرب من هنا .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c53c1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c53c1_row5_col0\" class=\"data row5 col0\" >11</td>\n",
       "      <td id=\"T_c53c1_row5_col1\" class=\"data row5 col1\" >corpus-6-test-corpus-26-train</td>\n",
       "      <td id=\"T_c53c1_row5_col2\" class=\"data row5 col2\" >سير نيشان حتا تشوف صيدلية.</td>\n",
       "      <td id=\"T_c53c1_row5_col3\" class=\"data row5 col3\" >استمر في السير في هذا الطريق حتى تجد صيدلية .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c53c1_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c53c1_row6_col0\" class=\"data row6 col0\" >12</td>\n",
       "      <td id=\"T_c53c1_row6_col1\" class=\"data row6 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_c53c1_row6_col2\" class=\"data row6 col2\" >شنو هو اجدد لون هاد الموسم؟</td>\n",
       "      <td id=\"T_c53c1_row6_col3\" class=\"data row6 col3\" >ما هو أحدث لون هذا الموسم .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c53c1_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c53c1_row7_col0\" class=\"data row7 col0\" >14</td>\n",
       "      <td id=\"T_c53c1_row7_col1\" class=\"data row7 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_c53c1_row7_col2\" class=\"data row7 col2\" >في الحالة ديالي، راه غالبا على الخدمة، قليل للمتعة.</td>\n",
       "      <td id=\"T_c53c1_row7_col3\" class=\"data row7 col3\" >في حالتي ، غالباً ما يكون من أجل العمل ونادراً ما يكون للاستمتاع .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c53c1_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c53c1_row8_col0\" class=\"data row8 col0\" >15</td>\n",
       "      <td id=\"T_c53c1_row8_col1\" class=\"data row8 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_c53c1_row8_col2\" class=\"data row8 col2\" >غادي نبقا يومين.</td>\n",
       "      <td id=\"T_c53c1_row8_col3\" class=\"data row8 col3\" >سأقيم لمدة يومين .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c53c1_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c53c1_row9_col0\" class=\"data row9 col0\" >16</td>\n",
       "      <td id=\"T_c53c1_row9_col1\" class=\"data row9 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_c53c1_row9_col2\" class=\"data row9 col2\" >بغيت بيرمانونت مجهد.</td>\n",
       "      <td id=\"T_c53c1_row9_col3\" class=\"data row9 col3\" >أريد تمويج متقارب بشعري</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Chemin vers votre fichier CSV\n",
    "chemin_fichier_csv = 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR_fusionne_7.csv'\n",
    "\n",
    "# Lire les 10 premières lignes du fichier CSV\n",
    "try:\n",
    "    df = pd.read_csv(chemin_fichier_csv)\n",
    "    display(HTML(df.head(10).style.set_table_styles([{'selector': 'th', 'props': [('background', '#F0F8FF')]}]).render()))\n",
    "except FileNotFoundError:\n",
    "    print(\"Le fichier spécifié n'a pas été trouvé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "222763c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MouadKHAZNAOUI\\AppData\\Local\\Temp\\ipykernel_6924\\446281448.py:11: FutureWarning: this method is deprecated in favour of `Styler.to_html()`\n",
      "  display(HTML(df_random.style.set_table_styles([{'selector': 'th', 'props': [('background', '#F0F8FF')]}]).render()))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a32a6 th {\n",
       "  background: #F0F8FF;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a32a6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a32a6_level0_col0\" class=\"col_heading level0 col0\" >sentID.BTEC</th>\n",
       "      <th id=\"T_a32a6_level0_col1\" class=\"col_heading level0 col1\" >split_RAB</th>\n",
       "      <th id=\"T_a32a6_level0_col2\" class=\"col_heading level0 col2\" >sent_RAB</th>\n",
       "      <th id=\"T_a32a6_level0_col3\" class=\"col_heading level0 col3\" >sent_MSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a32a6_level0_row0\" class=\"row_heading level0 row0\" >10425</th>\n",
       "      <td id=\"T_a32a6_row0_col0\" class=\"data row0 col0\" >17366</td>\n",
       "      <td id=\"T_a32a6_row0_col1\" class=\"data row0 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_a32a6_row0_col2\" class=\"data row0 col2\" >واش يمكن ليك تأكد حجز الرحلة ديال اطناش أكتوبر؟</td>\n",
       "      <td id=\"T_a32a6_row0_col3\" class=\"data row0 col3\" >هل يمكنكم التأكيد علي حجزي لرحلة الطيران يوم الثاني عشر من أكتوبر ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a32a6_level0_row1\" class=\"row_heading level0 row1\" >8836</th>\n",
       "      <td id=\"T_a32a6_row1_col0\" class=\"data row1 col0\" >14713</td>\n",
       "      <td id=\"T_a32a6_row1_col1\" class=\"data row1 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_a32a6_row1_col2\" class=\"data row1 col2\" >أش من طوبيس كيمشي للمحطة المركزية؟</td>\n",
       "      <td id=\"T_a32a6_row1_col3\" class=\"data row1 col3\" >أي أتوبيس يتوجه إلى المحطة المركزية ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a32a6_level0_row2\" class=\"row_heading level0 row2\" >4051</th>\n",
       "      <td id=\"T_a32a6_row2_col0\" class=\"data row2 col0\" >6798</td>\n",
       "      <td id=\"T_a32a6_row2_col1\" class=\"data row2 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_a32a6_row2_col2\" class=\"data row2 col2\" >هاد لكسوا ماكاتجيش معايا.</td>\n",
       "      <td id=\"T_a32a6_row2_col3\" class=\"data row2 col3\" >هذا الفستان لا يناسبني .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a32a6_level0_row3\" class=\"row_heading level0 row3\" >3572</th>\n",
       "      <td id=\"T_a32a6_row3_col0\" class=\"data row3 col0\" >6024</td>\n",
       "      <td id=\"T_a32a6_row3_col1\" class=\"data row3 col1\" >corpus-6-test-corpus-26-test</td>\n",
       "      <td id=\"T_a32a6_row3_col2\" class=\"data row3 col2\" >فهمت، ولا مكانعرف نقولهه.</td>\n",
       "      <td id=\"T_a32a6_row3_col3\" class=\"data row3 col3\" >أفهم ، لكن لا أستطيع أن أقولها .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a32a6_level0_row4\" class=\"row_heading level0 row4\" >3034</th>\n",
       "      <td id=\"T_a32a6_row4_col0\" class=\"data row4 col0\" >5099</td>\n",
       "      <td id=\"T_a32a6_row4_col1\" class=\"data row4 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_a32a6_row4_col2\" class=\"data row4 col2\" >انا فلاح.</td>\n",
       "      <td id=\"T_a32a6_row4_col3\" class=\"data row4 col3\" >إنني مزارع .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a32a6_level0_row5\" class=\"row_heading level0 row5\" >8043</th>\n",
       "      <td id=\"T_a32a6_row5_col0\" class=\"data row5 col0\" >13408</td>\n",
       "      <td id=\"T_a32a6_row5_col1\" class=\"data row5 col1\" >corpus-6-test-corpus-26-train</td>\n",
       "      <td id=\"T_a32a6_row5_col2\" class=\"data row5 col2\" >وقتاش غاديا اتلعب مباراة كرة القدم؟</td>\n",
       "      <td id=\"T_a32a6_row5_col3\" class=\"data row5 col3\" >متى تقام مباراة كرة القدم ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a32a6_level0_row6\" class=\"row_heading level0 row6\" >11581</th>\n",
       "      <td id=\"T_a32a6_row6_col0\" class=\"data row6 col0\" >19272</td>\n",
       "      <td id=\"T_a32a6_row6_col1\" class=\"data row6 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_a32a6_row6_col2\" class=\"data row6 col2\" >نعم، واش يمكن لينا نحصلو على قائمة التحلية؟</td>\n",
       "      <td id=\"T_a32a6_row6_col3\" class=\"data row6 col3\" >نعم . هل يمكننا الإطلاع على قائمة الحلوى ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a32a6_level0_row7\" class=\"row_heading level0 row7\" >646</th>\n",
       "      <td id=\"T_a32a6_row7_col0\" class=\"data row7 col0\" >1046</td>\n",
       "      <td id=\"T_a32a6_row7_col1\" class=\"data row7 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_a32a6_row7_col2\" class=\"data row7 col2\" >بغيت شي حاجة لي تجي مع هادا.</td>\n",
       "      <td id=\"T_a32a6_row7_col3\" class=\"data row7 col3\" >أريد شيئاً يناسب هذا .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a32a6_level0_row8\" class=\"row_heading level0 row8\" >288</th>\n",
       "      <td id=\"T_a32a6_row8_col0\" class=\"data row8 col0\" >490</td>\n",
       "      <td id=\"T_a32a6_row8_col1\" class=\"data row8 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_a32a6_row8_col2\" class=\"data row8 col2\" >كاي قرصو.</td>\n",
       "      <td id=\"T_a32a6_row8_col3\" class=\"data row8 col3\" >أنهم يألمومنني .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a32a6_level0_row9\" class=\"row_heading level0 row9\" >11942</th>\n",
       "      <td id=\"T_a32a6_row9_col0\" class=\"data row9 col0\" >19867</td>\n",
       "      <td id=\"T_a32a6_row9_col1\" class=\"data row9 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_a32a6_row9_col2\" class=\"data row9 col2\" >بلا فطور و بلا عشا؟</td>\n",
       "      <td id=\"T_a32a6_row9_col3\" class=\"data row9 col3\" >باستثناء الإفطار والعشاء ؟</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Chemin vers votre fichier CSV\n",
    "chemin_fichier_csv = 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR_fusionne_7.csv'\n",
    "\n",
    "# Lire un échantillon aléatoire de 10 lignes du fichier CSV\n",
    "try:\n",
    "    df = pd.read_csv(chemin_fichier_csv)\n",
    "    df_random = df.sample(n=10)\n",
    "    display(HTML(df_random.style.set_table_styles([{'selector': 'th', 'props': [('background', '#F0F8FF')]}]).render()))\n",
    "except FileNotFoundError:\n",
    "    print(\"Le fichier spécifié n'a pas été trouvé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e44f231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MouadKHAZNAOUI\\AppData\\Local\\Temp\\ipykernel_6924\\1801262436.py:10: FutureWarning: this method is deprecated in favour of `Styler.to_html()`\n",
      "  display(HTML(df.head(10).style.set_table_styles([{'selector': 'th', 'props': [('background', '#F0F8FF')]}]).render()))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fd517 th {\n",
       "  background: #F0F8FF;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fd517\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fd517_level0_col0\" class=\"col_heading level0 col0\" >sentID.BTEC</th>\n",
       "      <th id=\"T_fd517_level0_col1\" class=\"col_heading level0 col1\" >split_RAB</th>\n",
       "      <th id=\"T_fd517_level0_col2\" class=\"col_heading level0 col2\" >sent_RAB</th>\n",
       "      <th id=\"T_fd517_level0_col3\" class=\"col_heading level0 col3\" >sent_MSA</th>\n",
       "      <th id=\"T_fd517_level0_col4\" class=\"col_heading level0 col4\" >gen_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fd517_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fd517_row0_col0\" class=\"data row0 col0\" >sentID.BTEC</td>\n",
       "      <td id=\"T_fd517_row0_col1\" class=\"data row0 col1\" >split_RAB</td>\n",
       "      <td id=\"T_fd517_row0_col2\" class=\"data row0 col2\" >sent_RAB</td>\n",
       "      <td id=\"T_fd517_row0_col3\" class=\"data row0 col3\" >sent_MSA</td>\n",
       "      <td id=\"T_fd517_row0_col4\" class=\"data row0 col4\" >sent_MSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd517_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fd517_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_fd517_row1_col1\" class=\"data row1 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_fd517_row1_col2\" class=\"data row1 col2\" >كاين في اللاخر ديال هاد القاعة. انجيب ليك شويا دابا. و إلا حتاجيتي شي حاجا اخرى، قولها ليا.</td>\n",
       "      <td id=\"T_fd517_row1_col3\" class=\"data row1 col3\" >إنها في أخر القاعة . سوف آتي لك ببعض منها الآن . إذا أردت أي شيئاً آخر فقط أعلمني .</td>\n",
       "      <td id=\"T_fd517_row1_col4\" class=\"data row1 col4\" >It's at the end of the hall. I will bring you some of them now. If you want anything else just let me know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd517_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_fd517_row2_col0\" class=\"data row2 col0\" >2</td>\n",
       "      <td id=\"T_fd517_row2_col1\" class=\"data row2 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_fd517_row2_col2\" class=\"data row2 col2\" >واش كا دير التعديلات؟</td>\n",
       "      <td id=\"T_fd517_row2_col3\" class=\"data row2 col3\" >هل تقومون بعمل تعديلات ؟</td>\n",
       "      <td id=\"T_fd517_row2_col4\" class=\"data row2 col4\" >Do you make modifications?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd517_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_fd517_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_fd517_row3_col1\" class=\"data row3 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_fd517_row3_col2\" class=\"data row3 col2\" >بغينا ناخدو طابلة حدا الشرجم.</td>\n",
       "      <td id=\"T_fd517_row3_col3\" class=\"data row3 col3\" >نريد مائدة بجانب النافذة .</td>\n",
       "      <td id=\"T_fd517_row3_col4\" class=\"data row3 col4\" >We want a table by the window.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd517_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_fd517_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_fd517_row4_col1\" class=\"data row4 col1\" >corpus-6-test-corpus-26-train</td>\n",
       "      <td id=\"T_fd517_row4_col2\" class=\"data row4 col2\" >راه تما، مقابل مكتب استعلامات السياح بالضبط.</td>\n",
       "      <td id=\"T_fd517_row4_col3\" class=\"data row4 col3\" >هناك ، أمام بيانات السائح تماما .</td>\n",
       "      <td id=\"T_fd517_row4_col4\" class=\"data row4 col4\" >There, right in front of the tourist data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd517_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_fd517_row5_col0\" class=\"data row5 col0\" >9</td>\n",
       "      <td id=\"T_fd517_row5_col1\" class=\"data row5 col1\" >corpus-6-test-corpus-26-train</td>\n",
       "      <td id=\"T_fd517_row5_col2\" class=\"data row5 col2\" >ما عمري سمعت هاد العنوان هنايا.</td>\n",
       "      <td id=\"T_fd517_row5_col3\" class=\"data row5 col3\" >لم اسمع بهذا العنوان من قبل بالقرب من هنا .</td>\n",
       "      <td id=\"T_fd517_row5_col4\" class=\"data row5 col4\" >I've never heard of this address near here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd517_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_fd517_row6_col0\" class=\"data row6 col0\" >11</td>\n",
       "      <td id=\"T_fd517_row6_col1\" class=\"data row6 col1\" >corpus-6-test-corpus-26-train</td>\n",
       "      <td id=\"T_fd517_row6_col2\" class=\"data row6 col2\" >سير نيشان حتا تشوف صيدلية.</td>\n",
       "      <td id=\"T_fd517_row6_col3\" class=\"data row6 col3\" >استمر في السير في هذا الطريق حتى تجد صيدلية .</td>\n",
       "      <td id=\"T_fd517_row6_col4\" class=\"data row6 col4\" >Continue down this road until you find a pharmacy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd517_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_fd517_row7_col0\" class=\"data row7 col0\" >12</td>\n",
       "      <td id=\"T_fd517_row7_col1\" class=\"data row7 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_fd517_row7_col2\" class=\"data row7 col2\" >شنو هو اجدد لون هاد الموسم؟</td>\n",
       "      <td id=\"T_fd517_row7_col3\" class=\"data row7 col3\" >ما هو أحدث لون هذا الموسم .</td>\n",
       "      <td id=\"T_fd517_row7_col4\" class=\"data row7 col4\" >What is the latest color this season?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd517_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_fd517_row8_col0\" class=\"data row8 col0\" >14</td>\n",
       "      <td id=\"T_fd517_row8_col1\" class=\"data row8 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_fd517_row8_col2\" class=\"data row8 col2\" >في الحالة ديالي، راه غالبا على الخدمة، قليل للمتعة.</td>\n",
       "      <td id=\"T_fd517_row8_col3\" class=\"data row8 col3\" >في حالتي ، غالباً ما يكون من أجل العمل ونادراً ما يكون للاستمتاع .</td>\n",
       "      <td id=\"T_fd517_row8_col4\" class=\"data row8 col4\" >In my case, it's often for work and rarely for enjoyment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fd517_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_fd517_row9_col0\" class=\"data row9 col0\" >15</td>\n",
       "      <td id=\"T_fd517_row9_col1\" class=\"data row9 col1\" >corpus-6-train</td>\n",
       "      <td id=\"T_fd517_row9_col2\" class=\"data row9 col2\" >غادي نبقا يومين.</td>\n",
       "      <td id=\"T_fd517_row9_col3\" class=\"data row9 col3\" >سأقيم لمدة يومين .</td>\n",
       "      <td id=\"T_fd517_row9_col4\" class=\"data row9 col4\" >I will stay for two days.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Chemin vers votre fichier CSV\n",
    "chemin_fichier_csv = 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR_output_with_translation.csv'\n",
    "\n",
    "# Lire les 10 premières lignes du fichier CSV\n",
    "try:\n",
    "    df = pd.read_csv(chemin_fichier_csv)\n",
    "    display(HTML(df.head(10).style.set_table_styles([{'selector': 'th', 'props': [('background', '#F0F8FF')]}]).render()))\n",
    "except FileNotFoundError:\n",
    "    print(\"Le fichier spécifié n'a pas été trouvé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72a2a3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation in progress...\n",
      "Progress: 100.01% (Processed 12001/12000 lines)\n",
      "Translation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def translate_text(text, dest_language='en'):\n",
    "    translated_text = GoogleTranslator(source='ar', target=dest_language).translate(text)\n",
    "    return translated_text\n",
    "\n",
    "def translate_csv(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as csv_input, \\\n",
    "         open(output_file, 'a', newline='', encoding='utf-8') as csv_output:  # Changed mode to 'a' for append\n",
    "\n",
    "        reader = csv.DictReader(csv_input)\n",
    "        fieldnames = reader.fieldnames + ['gen_en']  # Adding a new field for English translation\n",
    "        writer = csv.DictWriter(csv_output, fieldnames=fieldnames)\n",
    "\n",
    "        total_lines = sum(1 for line in csv_input)  # Count total lines in the input CSV\n",
    "        csv_input.seek(0)  # Reset file pointer\n",
    "\n",
    "        print(\"Translation in progress...\")\n",
    "\n",
    "        # Skip lines until reaching line 2295\n",
    "        for _ in range(5997):\n",
    "            next(reader)\n",
    "\n",
    "        for i, row in enumerate(reader, 5998):  # Start counting from line 2296\n",
    "            arabic_text = row['sent_MSA']\n",
    "            english_text = translate_text(arabic_text)\n",
    "            row['gen_en'] = english_text\n",
    "            writer.writerow(row)\n",
    "\n",
    "            # Afficher l'avancement\n",
    "            progress = i / total_lines * 100\n",
    "            print(f\"Progress: {progress:.2f}% (Processed {i}/{total_lines} lines)\", end='\\r', flush=True)\n",
    "\n",
    "    print(\"\\nTranslation completed successfully!\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "translate_csv('C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR_fusionne_7.csv', 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR_output_with_translation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "381df42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as csv_input, \\\n",
    "         open(output_file, 'w', encoding='utf-8') as txt_output:\n",
    "\n",
    "        reader = csv.DictReader(csv_input)\n",
    "        translations = []\n",
    "\n",
    "        for row in reader:\n",
    "            translation = {\n",
    "                \"translation\": {\n",
    "                    \"sentID.BTEC\": row[\"sentID.BTEC\"],\n",
    "                    \"split_RAB\": row[\"split_RAB\"],\n",
    "                    \"gen_en\": row[\"gen_en\"],\n",
    "                    \"sent_RAB\": row[\"sent_RAB\"],\n",
    "                    \"sent_MSA\": row[\"sent_MSA\"]\n",
    "                }\n",
    "            }\n",
    "            translations.append(translation)\n",
    "\n",
    "        json.dump(translations, txt_output, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Exemple d'utilisation\n",
    "csv_to_json('C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR_output_with_translation.csv', 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\output.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a081990e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     idx                                            English  \\\n",
      "0   4000                                      Good evening!   \n",
      "1   4001                  What do you have on the pressure?   \n",
      "2   4002                                   On the pressure?   \n",
      "3   4003                                    i don't follow.   \n",
      "4   4004  I am pretty stressed out with work at the moment.   \n",
      "5   4005                 I am pretty stressed out right now   \n",
      "6   4006                             is that what you mean?   \n",
      "7   4007    No, I just wanted to ask what beers do you have   \n",
      "8   4008               If you have wine, I'll be fine, too.   \n",
      "9   4009                                                oh!   \n",
      "10  4010                                             sorry!   \n",
      "11  4011              It's quite bitter but very refreshing   \n",
      "12  4012                      I wouldn't recommend the meat   \n",
      "13  4013                 after all, we are beer specialists   \n",
      "14  4014                                           Perfect!   \n",
      "15  4015                        I like a lot of bitter beer   \n",
      "16  4016                          Could you pour me a pint?   \n",
      "17  4017                      Then I'll have a whole liter!   \n",
      "18  4018                           What do you have to eat?   \n",
      "19  4019                           What do you have to eat?   \n",
      "\n",
      "                                 Darija_arabic  \\\n",
      "0                                 ماساء لخاير!   \n",
      "1                          أش عانداك علا ضاغط?   \n",
      "2                                    علا ضاغط?   \n",
      "3                                    مافهامتش?   \n",
      "4    أنا ماتواتار بزاف فلخادما بزاف فهاد لواقت   \n",
      "5                        أنا مسترسّي شويا دابا   \n",
      "6                          واش هادشي ليكاتعني?   \n",
      "7   لا بغيت غير نساوال علا أنواع لبيرا ليعنداك   \n",
      "8           إلا كان عنداك شراب غادي نكون بيخير   \n",
      "9                                         أُه!   \n",
      "10                                     سماحلي!   \n",
      "11              هييا مورا شويا والاكين مونعيشا   \n",
      "12                            ماكانوصّيش بلّحم   \n",
      "13          أل جيتي تشوف, حنا ماتخاسين ف لبيرا   \n",
      "14                                     مومتاز!   \n",
      "15             أنا كانبغي بزاف ت لبيرّا لمورّا   \n",
      "16                 تاقدار تكوب لييا شي كوييّس?   \n",
      "17             أُ من باعد غدي ناخود إطرو كامل!   \n",
      "18                          أشنو عاندك لماكلا?   \n",
      "19                           شنو عندك فلماكلا?   \n",
      "\n",
      "                                                  MSA  \\\n",
      "0                                        مساء الخير!    \n",
      "1                                 ماذا لديك عن الضغط؟   \n",
      "2                                          تحت الضغط؟   \n",
      "3                                            لا أفهم.   \n",
      "4          أنا متوتر جدًا بسبب العمل في الوقت الحالي.   \n",
      "5                                 أنا متوتر جدًا الآن   \n",
      "6                                    هل هذا ما تقصده؟   \n",
      "7   لا، أردت فقط أن أسأل، ما هي أنواع البيرة التي ...   \n",
      "8                إذا كان لديك نبيذ، سأكون بخير أيضًا.   \n",
      "9                                                 آه!   \n",
      "10                                               آسف!   \n",
      "11                       إنه مر جداً لكنه منعش للغاية   \n",
      "12                                     لا أنصح باللحم   \n",
      "13                  في النهاية، نحن متخصصون في البيرة   \n",
      "14                                             مثالي!   \n",
      "15                     أنا أحب الكثير من البيرة المرة   \n",
      "16                        هل يمكنك أن تصب لي نصف لتر؟   \n",
      "17                          عندها سأحصل على لتر كامل!   \n",
      "18                                  ماذا لديكم للأكل؟   \n",
      "19                                  ماذا لديكم للأكل؟   \n",
      "\n",
      "                    Darija_arabic correction  \\\n",
      "0                                مْسا الخير!   \n",
      "1                        آش عندك على الضغط ؟   \n",
      "2                                 على الضغط؟   \n",
      "3                                   مافهمتش.   \n",
      "4       أنا متوتر بزاف مع الخدمة هاد الساعة.   \n",
      "5                     أنا مستريسّي بزاف دابا   \n",
      "6                                        NaN   \n",
      "7   لا بغيت غير نسول علا أنواع لبيرا ليعندك.   \n",
      "8        إلا كان عندك الشراب غادي نكون بيخير   \n",
      "9                                        آه!   \n",
      "10                                    سمحلي!   \n",
      "11                 هوا مْرْ شويا ولكن مُنعش.   \n",
      "12                            مانصحكش بلّحم.   \n",
      "13     إلا جيتي تشوف، حنا متخصْصِين ف لبيرا.   \n",
      "14                                   مُمتاز!   \n",
      "15       أنا كايعجبوني بزاف ت لبيرّات مرِّين   \n",
      "16                     واخا تكُبلي شي كويّس؟   \n",
      "17           أُ من بعد غادي ناخُد إطرو كامل!   \n",
      "18                                       NaN   \n",
      "19                                       NaN   \n",
      "\n",
      "                     Darija_arabic_corrected  \n",
      "0                                مْسا الخير!  \n",
      "1                        آش عندك على الضغط ؟  \n",
      "2                                 على الضغط؟  \n",
      "3                                   مافهمتش.  \n",
      "4       أنا متوتر بزاف مع الخدمة هاد الساعة.  \n",
      "5                     أنا مستريسّي بزاف دابا  \n",
      "6                        واش هادشي ليكاتعني?  \n",
      "7   لا بغيت غير نسول علا أنواع لبيرا ليعندك.  \n",
      "8        إلا كان عندك الشراب غادي نكون بيخير  \n",
      "9                                        آه!  \n",
      "10                                    سمحلي!  \n",
      "11                 هوا مْرْ شويا ولكن مُنعش.  \n",
      "12                            مانصحكش بلّحم.  \n",
      "13     إلا جيتي تشوف، حنا متخصْصِين ف لبيرا.  \n",
      "14                                   مُمتاز!  \n",
      "15       أنا كايعجبوني بزاف ت لبيرّات مرِّين  \n",
      "16                     واخا تكُبلي شي كويّس؟  \n",
      "17           أُ من بعد غادي ناخُد إطرو كامل!  \n",
      "18                        أشنو عاندك لماكلا?  \n",
      "19                         شنو عندك فلماكلا?  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier CSV\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\group_b.csv\", skiprows=3)\n",
    "\n",
    "# Sélectionner les colonnes nécessaires\n",
    "df = df[['idx', 'English', 'Darija_arabic', 'MSA', 'Darija_arabic correction']]\n",
    "\n",
    "# Créer la nouvelle colonne Darija_arabic_corrected\n",
    "df['Darija_arabic_corrected'] = df.apply(lambda row: row['Darija_arabic correction'] if pd.notnull(row['Darija_arabic correction']) else row['Darija_arabic'], axis=1)\n",
    "\n",
    "# Afficher le DataFrame résultant\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c24d1fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     idx                                            English  \\\n",
      "0   4000                                      Good evening!   \n",
      "1   4001                  What do you have on the pressure?   \n",
      "2   4002                                   On the pressure?   \n",
      "3   4003                                    i don't follow.   \n",
      "4   4004  I am pretty stressed out with work at the moment.   \n",
      "5   4005                 I am pretty stressed out right now   \n",
      "6   4006                             is that what you mean?   \n",
      "7   4007    No, I just wanted to ask what beers do you have   \n",
      "8   4008               If you have wine, I'll be fine, too.   \n",
      "9   4009                                                oh!   \n",
      "10  4010                                             sorry!   \n",
      "11  4011              It's quite bitter but very refreshing   \n",
      "12  4012                      I wouldn't recommend the meat   \n",
      "13  4013                 after all, we are beer specialists   \n",
      "14  4014                                           Perfect!   \n",
      "15  4015                        I like a lot of bitter beer   \n",
      "16  4016                          Could you pour me a pint?   \n",
      "17  4017                      Then I'll have a whole liter!   \n",
      "18  4018                           What do you have to eat?   \n",
      "19  4019                           What do you have to eat?   \n",
      "\n",
      "                                                  MSA  \\\n",
      "0                                        مساء الخير!    \n",
      "1                                 ماذا لديك عن الضغط؟   \n",
      "2                                          تحت الضغط؟   \n",
      "3                                            لا أفهم.   \n",
      "4          أنا متوتر جدًا بسبب العمل في الوقت الحالي.   \n",
      "5                                 أنا متوتر جدًا الآن   \n",
      "6                                    هل هذا ما تقصده؟   \n",
      "7   لا، أردت فقط أن أسأل، ما هي أنواع البيرة التي ...   \n",
      "8                إذا كان لديك نبيذ، سأكون بخير أيضًا.   \n",
      "9                                                 آه!   \n",
      "10                                               آسف!   \n",
      "11                       إنه مر جداً لكنه منعش للغاية   \n",
      "12                                     لا أنصح باللحم   \n",
      "13                  في النهاية، نحن متخصصون في البيرة   \n",
      "14                                             مثالي!   \n",
      "15                     أنا أحب الكثير من البيرة المرة   \n",
      "16                        هل يمكنك أن تصب لي نصف لتر؟   \n",
      "17                          عندها سأحصل على لتر كامل!   \n",
      "18                                  ماذا لديكم للأكل؟   \n",
      "19                                  ماذا لديكم للأكل؟   \n",
      "\n",
      "                     Darija_arabic_corrected  \n",
      "0                                مْسا الخير!  \n",
      "1                        آش عندك على الضغط ؟  \n",
      "2                                 على الضغط؟  \n",
      "3                                   مافهمتش.  \n",
      "4       أنا متوتر بزاف مع الخدمة هاد الساعة.  \n",
      "5                     أنا مستريسّي بزاف دابا  \n",
      "6                        واش هادشي ليكاتعني?  \n",
      "7   لا بغيت غير نسول علا أنواع لبيرا ليعندك.  \n",
      "8        إلا كان عندك الشراب غادي نكون بيخير  \n",
      "9                                        آه!  \n",
      "10                                    سمحلي!  \n",
      "11                 هوا مْرْ شويا ولكن مُنعش.  \n",
      "12                            مانصحكش بلّحم.  \n",
      "13     إلا جيتي تشوف، حنا متخصْصِين ف لبيرا.  \n",
      "14                                   مُمتاز!  \n",
      "15       أنا كايعجبوني بزاف ت لبيرّات مرِّين  \n",
      "16                     واخا تكُبلي شي كويّس؟  \n",
      "17           أُ من بعد غادي ناخُد إطرو كامل!  \n",
      "18                        أشنو عاندك لماكلا?  \n",
      "19                         شنو عندك فلماكلا?  \n"
     ]
    }
   ],
   "source": [
    "# Supprimer les colonnes 'Darija_arabic' et 'Darija_arabic correction'\n",
    "df.drop(columns=['Darija_arabic', 'Darija_arabic correction'], inplace=True)\n",
    "\n",
    "# Afficher le DataFrame résultant\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04fc0be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier CSV a été enregistré avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Convertir le DataFrame en un nouveau fichier CSV\n",
    "df.to_csv(\"C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\Dataset_Group_B.csv\", index=False)\n",
    "\n",
    "# Confirmer l'enregistrement\n",
    "print(\"Le fichier CSV a été enregistré avec succès.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e27e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as csv_input, \\\n",
    "         open(output_file, 'w', encoding='utf-8') as txt_output:\n",
    "\n",
    "        reader = csv.DictReader(csv_input)\n",
    "        translations = []\n",
    "\n",
    "        for row in reader:\n",
    "            translation = {\n",
    "                \"translation\": {\n",
    "                    \"idx\": row[\"sentID.BTEC\"],\n",
    "                    \"English\": row[\"gen_en\"],\n",
    "                    \"Darija\": row[\"sent_RAB\"],\n",
    "                    \"MSA\": row[\"sent_MSA\"]\n",
    "                }\n",
    "            }\n",
    "            translations.append(translation)\n",
    "\n",
    "        json.dump(translations, txt_output, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Exemple d'utilisation\n",
    "csv_to_json('C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR_output_with_translation.csv', 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\Augmented_Dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fac9c653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as csv_input, \\\n",
    "         open(output_file, 'w', encoding='utf-8') as txt_output:\n",
    "\n",
    "        reader = csv.DictReader(csv_input)\n",
    "        translations = []\n",
    "\n",
    "        for row in reader:\n",
    "            translation = {\n",
    "                \"idx\": row[\"idx\"],\n",
    "                \"English\": row[\"English\"],\n",
    "                \"Darija\": row[\"Darija_arabic_corrected\"],\n",
    "                \"MSA\": row[\"MSA\"]\n",
    "            }\n",
    "            translations.append(translation)\n",
    "\n",
    "        json.dump(translations, txt_output, ensure_ascii=False, indent=4)\n",
    "\n",
    "def csv_to_csv(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as csv_input, \\\n",
    "         open(output_file, 'w', encoding='utf-8', newline='') as csv_output:\n",
    "\n",
    "        reader = csv.DictReader(csv_input)\n",
    "        fieldnames = [\"idx\", \"English\", \"Darija\", \"MSA\"]\n",
    "        writer = csv.DictWriter(csv_output, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in reader:\n",
    "            writer.writerow({\n",
    "                \"idx\": row[\"idx\"],\n",
    "                \"English\": row[\"English\"],\n",
    "                \"Darija\": row[\"Darija_arabic_corrected\"],\n",
    "                \"MSA\": row[\"MSA\"]\n",
    "            })\n",
    "\n",
    "# Exemple d'utilisation\n",
    "csv_to_json('C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\Dataset_Group_B.csv', 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\Initial_Dataset.json')\n",
    "csv_to_csv('C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\Dataset_Group_B.csv', 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\Initial_Dataset.csv')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ec6227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as csv_input, \\\n",
    "         open(output_file, 'w', encoding='utf-8') as txt_output:\n",
    "\n",
    "        reader = csv.DictReader(csv_input)\n",
    "        translations = []\n",
    "\n",
    "        for row in reader:\n",
    "            translation = {\n",
    "                \"idx\": row[\"sentID.BTEC\"],\n",
    "                \"English\": row[\"gen_en\"],\n",
    "                \"Darija\": row[\"sent_RAB\"],\n",
    "                \"MSA\": row[\"sent_MSA\"]\n",
    "            }\n",
    "            translations.append(translation)\n",
    "\n",
    "        json.dump(translations, txt_output, ensure_ascii=False, indent=4)\n",
    "\n",
    "def csv_to_csv(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as csv_input, \\\n",
    "         open(output_file, 'w', encoding='utf-8', newline='') as csv_output:\n",
    "\n",
    "        reader = csv.DictReader(csv_input)\n",
    "        fieldnames = [\"idx\", \"English\", \"Darija\", \"MSA\"]\n",
    "        writer = csv.DictWriter(csv_output, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in reader:\n",
    "            writer.writerow({\n",
    "                \"idx\": row[\"sentID.BTEC\"],\n",
    "                \"English\": row[\"gen_en\"],\n",
    "                \"Darija\": row[\"sent_RAB\"],\n",
    "                \"MSA\": row[\"sent_MSA\"]\n",
    "            })\n",
    "\n",
    "# Exemple d'utilisation\n",
    "csv_to_json('C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR_output_with_translation.csv', 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\Augmented_Dataset.json')\n",
    "csv_to_csv('C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\MADAR_output_with_translation.csv', 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\Augmented_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6c7f762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes vides par colonne :\n",
      "Colonne 'idx' : 0 lignes vides\n",
      "Colonne 'English' : 0 lignes vides\n",
      "Colonne 'Darija' : 0 lignes vides\n",
      "Colonne 'MSA' : 0 lignes vides\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_empty_lines_per_column(filename):\n",
    "    # Charger le fichier CSV dans un DataFrame pandas\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Initialiser un dictionnaire pour stocker le nombre de lignes vides par colonne\n",
    "    empty_lines_per_column = {}\n",
    "\n",
    "    # Parcourir chaque colonne du DataFrame\n",
    "    for column in df.columns:\n",
    "        # Compter le nombre de lignes vides dans la colonne\n",
    "        empty_lines_per_column[column] = df[column].isnull().sum()\n",
    "\n",
    "    # Retourner le dictionnaire contenant le nombre de lignes vides par colonne\n",
    "    return empty_lines_per_column\n",
    "\n",
    "# Appel de la fonction avec le nom du fichier CSV en argument\n",
    "filename = 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\Augmented_Dataset.csv'\n",
    "empty_lines_per_column = count_empty_lines_per_column(filename)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Nombre de lignes vides par colonne :\")\n",
    "for column, count in empty_lines_per_column.items():\n",
    "    print(f\"Colonne '{column}' : {count} lignes vides\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95da52ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes vides par colonne :\n",
      "Colonne 'idx' : 0 lignes vides\n",
      "Colonne 'English' : 0 lignes vides\n",
      "Colonne 'Darija' : 0 lignes vides\n",
      "Colonne 'MSA' : 0 lignes vides\n"
     ]
    }
   ],
   "source": [
    "# Appel de la fonction avec le nom du fichier CSV en argument\n",
    "filename2 = 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\Initial_Dataset.csv'\n",
    "empty_lines_per_column2 = count_empty_lines_per_column(filename2)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Nombre de lignes vides par colonne :\")\n",
    "for column, count in empty_lines_per_column2.items():\n",
    "    print(f\"Colonne '{column}' : {count} lignes vides\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa5a4c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucune ligne vide n'a été trouvée dans la colonne 'MSA'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_empty_line_index(filename, column_name):\n",
    "    # Charger le fichier CSV dans un DataFrame pandas\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Trouver l'indice de la première ligne vide dans la colonne spécifiée\n",
    "    empty_line_index = df[df[column_name].isnull()].index.tolist()\n",
    "\n",
    "    # Retourner l'indice de la ligne vide\n",
    "    return empty_line_index\n",
    "\n",
    "column_name = 'MSA'\n",
    "\n",
    "# Appel de la fonction pour trouver l'indice de la ligne vide dans la colonne spécifiée\n",
    "empty_line_index = find_empty_line_index(filename2, column_name)\n",
    "\n",
    "# Affichage du résultat\n",
    "if empty_line_index:\n",
    "    print(f\"L'indice de la première ligne vide dans la colonne '{column_name}' est : {empty_line_index[0]}\")\n",
    "else:\n",
    "    print(f\"Aucune ligne vide n'a été trouvée dans la colonne '{column_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a8072d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json_and_csv(input_file, output_csv, output_json, num_rows=10000):\n",
    "    with open(input_file, 'r', encoding='utf-8') as csv_input, \\\n",
    "         open(output_csv, 'w', encoding='utf-8', newline='') as csv_output, \\\n",
    "         open(output_json, 'w', encoding='utf-8') as json_output:\n",
    "\n",
    "        reader = csv.DictReader(csv_input)\n",
    "        fieldnames = reader.fieldnames\n",
    "        writer_csv = csv.DictWriter(csv_output, fieldnames=fieldnames)\n",
    "        writer_csv.writeheader()\n",
    "        \n",
    "        translations = []\n",
    "\n",
    "        for idx, row in enumerate(reader):\n",
    "            if idx >= num_rows:\n",
    "                break\n",
    "\n",
    "            writer_csv.writerow(row)\n",
    "\n",
    "            translation = {\n",
    "                \"idx\": row[\"idx\"],\n",
    "                \"English\": row[\"English\"],\n",
    "                \"Darija\": row[\"Darija\"],\n",
    "                \"MSA\": row[\"MSA\"]\n",
    "            }\n",
    "            translations.append(translation)\n",
    "\n",
    "        json.dump(translations, json_output, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Exemple d'utilisation\n",
    "csv_to_json_and_csv('C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\Augmented_Dataset.csv',\n",
    "                    'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\Augmented_Dataset_10000.csv',\n",
    "                    'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\Augmented_Dataset_10000.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a8448edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion terminée.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def convert_json_to_txt(json_filename, txt_filename):\n",
    "    # Ouvrir le fichier JSON en mode lecture\n",
    "    with open(json_filename, 'r', encoding='utf-8') as json_file:\n",
    "        # Charger les données JSON\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Ouvrir le fichier texte en mode écriture\n",
    "    with open(txt_filename, 'w', encoding='utf-8') as txt_file:\n",
    "        # Parcourir chaque élément dans la liste JSON\n",
    "        for item in data:\n",
    "            # Construire la ligne de texte au format spécifié\n",
    "            line = json.dumps({\"translation\": item}, ensure_ascii=False) + '\\n'\n",
    "            # Écrire la ligne dans le fichier texte\n",
    "            txt_file.write(line)\n",
    "\n",
    "# Nom des fichiers d'entrée et de sortie\n",
    "json_filename = 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\Initial_Dataset.json'\n",
    "txt_filename = 'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\Initial_Dataset.txt'\n",
    "\n",
    "# Appel de la fonction pour convertir le fichier JSON en texte au format spécifié\n",
    "convert_json_to_txt(json_filename, txt_filename)\n",
    "\n",
    "print(\"Conversion terminée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3718a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>English</th>\n",
       "      <th>Darija</th>\n",
       "      <th>MSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>It's at the end of the hall. I will bring you ...</td>\n",
       "      <td>كاين في اللاخر ديال هاد القاعة. انجيب ليك شويا...</td>\n",
       "      <td>إنها في أخر القاعة . سوف آتي لك ببعض منها الآن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Do you make modifications?</td>\n",
       "      <td>واش كا دير التعديلات؟</td>\n",
       "      <td>هل تقومون بعمل تعديلات ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>We want a table by the window.</td>\n",
       "      <td>بغينا ناخدو طابلة حدا الشرجم.</td>\n",
       "      <td>نريد مائدة بجانب النافذة .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>There, right in front of the tourist data.</td>\n",
       "      <td>راه تما، مقابل مكتب استعلامات السياح بالضبط.</td>\n",
       "      <td>هناك ، أمام بيانات السائح تماما .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>I've never heard of this address near here.</td>\n",
       "      <td>ما عمري سمعت هاد العنوان هنايا.</td>\n",
       "      <td>لم اسمع بهذا العنوان من قبل بالقرب من هنا .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>Continue down this road until you find a pharm...</td>\n",
       "      <td>سير نيشان حتا تشوف صيدلية.</td>\n",
       "      <td>استمر في السير في هذا الطريق حتى تجد صيدلية .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>What is the latest color this season?</td>\n",
       "      <td>شنو هو اجدد لون هاد الموسم؟</td>\n",
       "      <td>ما هو أحدث لون هذا الموسم .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>In my case, it's often for work and rarely for...</td>\n",
       "      <td>في الحالة ديالي، راه غالبا على الخدمة، قليل لل...</td>\n",
       "      <td>في حالتي ، غالباً ما يكون من أجل العمل ونادراً...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>I will stay for two days.</td>\n",
       "      <td>غادي نبقا يومين.</td>\n",
       "      <td>سأقيم لمدة يومين .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>I want close waves in my hair</td>\n",
       "      <td>بغيت بيرمانونت مجهد.</td>\n",
       "      <td>أريد تمويج متقارب بشعري</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                            English                                             Darija                                                MSA\n",
       "0    0  It's at the end of the hall. I will bring you ...  كاين في اللاخر ديال هاد القاعة. انجيب ليك شويا...  إنها في أخر القاعة . سوف آتي لك ببعض منها الآن...\n",
       "1    2                         Do you make modifications?                              واش كا دير التعديلات؟                           هل تقومون بعمل تعديلات ؟\n",
       "2    4                     We want a table by the window.                      بغينا ناخدو طابلة حدا الشرجم.                         نريد مائدة بجانب النافذة .\n",
       "3    5         There, right in front of the tourist data.       راه تما، مقابل مكتب استعلامات السياح بالضبط.                  هناك ، أمام بيانات السائح تماما .\n",
       "4    9        I've never heard of this address near here.                    ما عمري سمعت هاد العنوان هنايا.        لم اسمع بهذا العنوان من قبل بالقرب من هنا .\n",
       "5   11  Continue down this road until you find a pharm...                         سير نيشان حتا تشوف صيدلية.      استمر في السير في هذا الطريق حتى تجد صيدلية .\n",
       "6   12              What is the latest color this season?                        شنو هو اجدد لون هاد الموسم؟                        ما هو أحدث لون هذا الموسم .\n",
       "7   14  In my case, it's often for work and rarely for...  في الحالة ديالي، راه غالبا على الخدمة، قليل لل...  في حالتي ، غالباً ما يكون من أجل العمل ونادراً...\n",
       "8   15                          I will stay for two days.                                   غادي نبقا يومين.                                 سأقيم لمدة يومين .\n",
       "9   16                      I want close waves in my hair                               بغيت بيرمانونت مجهد.                            أريد تمويج متقارب بشعري"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lecture du fichier CSV\n",
    "df = pd.read_csv(r'C:\\\\Users\\\\MouadKHAZNAOUI\\\\Downloads\\\\Augmented_Dataset.csv')\n",
    "\n",
    "# Affichage des 10 premières lignes\n",
    "df_head = df.head(10)\n",
    "\n",
    "# Affichage du tableau\n",
    "df_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d299303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
